name: CI/CD Pipeline
permissions:
  contents: read

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  test-backend:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: landscape_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres_password
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
          --health-start-period 30s
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install redis-cli
      run: sudo apt-get update && sudo apt-get install -y redis-tools
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: |
          requirements.txt
          requirements-dev.txt
        
    - name: Cache Python dependencies  
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.local/lib/python*/site-packages
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        pip install psycopg2-binary
        
    - name: Wait for services
      run: |
        # Wait for PostgreSQL with enhanced timeout and connection testing
        timeout 60 bash -c 'until pg_isready -h localhost -p 5432 -U postgres; do sleep 2; done'
        
        # Wait for Redis with enhanced timeout
        timeout 60 bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 2; done'
        
        # Additional connection validation
        python -c "
        import psycopg2
        import redis
        import time
        
        # Test PostgreSQL connection
        for i in range(10):
            try:
                conn = psycopg2.connect('postgresql://postgres:postgres_password@localhost:5432/landscape_test')
                conn.close()
                print('âœ… PostgreSQL connection successful')
                break
            except Exception as e:
                print(f'PostgreSQL attempt {i+1}: {e}')
                time.sleep(2)
        else:
            raise Exception('Failed to connect to PostgreSQL')
            
        # Test Redis connection  
        for i in range(10):
            try:
                r = redis.from_url('redis://localhost:6379/1')
                r.ping()
                print('âœ… Redis connection successful')
                break
            except Exception as e:
                print(f'Redis attempt {i+1}: {e}')
                time.sleep(2)
        else:
            raise Exception('Failed to connect to Redis')
        "
        
        echo "âœ… All services are ready"
        
    - name: Run database migrations
      env:
        DATABASE_URL: postgresql://postgres:postgres_password@localhost:5432/landscape_test?connect_timeout=30&application_name=ci_test
        PYTHONPATH: .
      run: |
        flask --app src.main db upgrade
        
    - name: Test backend with SQLite
      env:
        PYTHONPATH: .
        FLASK_ENV: testing
      run: |
        python -m pytest tests/ -v --tb=short --maxfail=5
        
    - name: Test backend with PostgreSQL
      env:
        DATABASE_URL: postgresql://postgres:postgres_password@localhost:5432/landscape_test?connect_timeout=30&application_name=ci_test
        REDIS_URL: redis://localhost:6379/1
        SECRET_KEY: test-secret-key-not-for-production
        PYTHONPATH: .
        FLASK_ENV: testing
      run: |
        python -m pytest tests/ -v --tb=short --maxfail=5

  test-frontend:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
        
    - name: Install dependencies
      run: |
        cd frontend
        npm ci --legacy-peer-deps
        
    - name: Run security audit
      run: |
        cd frontend
        npm audit --audit-level=moderate || echo "Security vulnerabilities found"
        
    - name: Lint frontend
      run: |
        cd frontend
        npm run lint
        
    - name: Build frontend
      run: |
        cd frontend
        npm run build
        
    - name: Test frontend with coverage
      run: |
        cd frontend
        npm run test:coverage -- --watchAll=false --ci --coverage --passWithNoTests
        
    - name: Check coverage thresholds
      run: |
        cd frontend
        if [ -f coverage/coverage-summary.json ]; then
          echo "Coverage summary found, checking thresholds..."
          
          # Install jq if not available
          which jq || (echo "Installing jq..." && sudo apt-get update && sudo apt-get install -y jq)
          
          # Extract coverage percentages (use default values if not found)
          LINES=$(cat coverage/coverage-summary.json | jq -r '.total.lines.pct // 0')
          FUNCTIONS=$(cat coverage/coverage-summary.json | jq -r '.total.functions.pct // 0')
          BRANCHES=$(cat coverage/coverage-summary.json | jq -r '.total.branches.pct // 0')
          STATEMENTS=$(cat coverage/coverage-summary.json | jq -r '.total.statements.pct // 0')
          
          echo "Coverage Report:"
          echo "Lines: ${LINES}%"
          echo "Functions: ${FUNCTIONS}%"
          echo "Branches: ${BRANCHES}%"
          echo "Statements: ${STATEMENTS}%"
          
          # For now, just report coverage without failing CI
          # TODO: Implement proper thresholds once tests are comprehensive
          echo "âœ… Coverage reported successfully"
        else
          echo "No coverage report found, skipping threshold check"
        fi
        
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      if: success()
      with:
        name: frontend-build
        path: frontend/dist/
        retention-days: 7
        
    - name: Upload coverage artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: frontend-coverage
        path: |
          frontend/coverage/
          !frontend/coverage/tmp/
        retention-days: 30

  code-quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Install redis-cli
      run: sudo apt-get update && sudo apt-get install -y redis-tools
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: |
          requirements.txt
          requirements-dev.txt
        
    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install black==24.3.0 flake8==7.0.0 isort==5.13.2 bandit==1.7.5 safety==3.0.1

    - name: Check Python formatting
      run: |
        black --check --line-length 88 src/ tests/ --diff
        
    - name: Check import sorting  
      run: |
        isort --check-only --profile black src/ tests/ --diff

    - name: Run Python linting
      run: |
        flake8 src/ tests/ --max-line-length=88 --extend-ignore=E203,W503,F401,F403,E402,C901,W291 --max-complexity=25
        
    - name: Run security linting
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
        
    - name: Check Python security
      run: |
        safety check --json || echo "Security vulnerabilities found"
        
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: bandit-report.json
        retention-days: 30

  integration-tests:
    needs: [test-backend, test-frontend]
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: landscape_integration_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres_password
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
          --health-start-period 30s
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install redis-cli
      run: sudo apt-get update && sudo apt-get install -y redis-tools
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: |
          requirements.txt
          requirements-dev.txt
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        pip install psycopg2-binary requests
        
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
        
    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci --legacy-peer-deps
        
    - name: Build frontend
      run: |
        cd frontend
        npm run build
        
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://postgres:postgres_password@localhost:5432/landscape_integration_test?connect_timeout=30&application_name=integration_test
        REDIS_URL: redis://localhost:6379/1
        SECRET_KEY: integration-test-secret-key
        FLASK_ENV: testing
        PYTHONPATH: .
      run: |
        # Enhanced service health validation
        echo "Validating service connections..."
        python -c "
        import psycopg2
        import redis
        import time
        
        # Test PostgreSQL connection
        for i in range(10):
            try:
                conn = psycopg2.connect('$DATABASE_URL')
                conn.close()
                print('âœ… PostgreSQL connection successful')
                break
            except Exception as e:
                print(f'PostgreSQL attempt {i+1}: {e}')
                time.sleep(2)
        else:
            raise Exception('Failed to connect to PostgreSQL')
            
        # Test Redis connection  
        for i in range(10):
            try:
                r = redis.from_url('$REDIS_URL')
                r.ping()
                print('âœ… Redis connection successful')
                break
            except Exception as e:
                print(f'Redis attempt {i+1}: {e}')
                time.sleep(2)
        else:
            raise Exception('Failed to connect to Redis')
        "
        
        # Setup database
        flask --app src.main db upgrade
        
        # Start backend in background with logging
        echo "Starting backend application..."
        python src/main.py > backend.log 2>&1 &
        BACKEND_PID=$!
        
        # Wait for backend to start with enhanced timeout
        echo "Waiting for backend to be ready..."
        timeout 60 bash -c 'until curl -f http://localhost:5000/health; do sleep 2; done'
        
        echo "Backend is ready, running integration tests..."
        
        # Test API endpoints with error handling
        set -e  # Exit on any error
        
        echo "Testing health endpoint..."
        curl -f http://localhost:5000/health
        
        echo "Testing dashboard stats..."
        curl -f http://localhost:5000/api/dashboard/stats
        
        echo "Testing CRUD operations..."
        
        # Test supplier creation
        SUPPLIER_RESPONSE=$(curl -X POST http://localhost:5000/api/suppliers \
          -H "Content-Type: application/json" \
          -d '{"name":"Test Supplier","contact_person":"John Doe","email":"john@test.com","phone":"123-456-7890","address":"123 Test St"}')
        
        echo "Supplier creation response: $SUPPLIER_RESPONSE"
        
        # Test supplier listing
        echo "Testing supplier listing..."
        curl -f http://localhost:5000/api/suppliers
        
        echo "âœ… All integration tests passed"
        
        # Cleanup
        kill $BACKEND_PID || true
        
    - name: Collect integration test artifacts
      if: always()
      run: |
        # Collect logs and any artifacts
        mkdir -p integration-artifacts
        
        # Copy backend log if it exists
        if [ -f backend.log ]; then
          cp backend.log integration-artifacts/
        fi
        
        # Create test summary
        echo "Integration Test Summary" > integration-artifacts/summary.txt
        echo "Timestamp: $(date)" >> integration-artifacts/summary.txt
        echo "Backend PID: $BACKEND_PID" >> integration-artifacts/summary.txt
        
    - name: Upload integration test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-artifacts
        path: integration-artifacts/
        retention-days: 7

  docker-build:
    needs: [test-backend, test-frontend, code-quality]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Build Docker images
      run: |
        # Validate docker compose configuration
        docker compose config > /dev/null
        
        # Build images
        docker compose build
        
        # Test with health checks
        docker compose up -d --wait --wait-timeout 300
        
        # Test backend endpoint (backend runs on port 5000)
        timeout 30 bash -c 'until curl -f http://localhost:5000/health; do sleep 2; done'
        
        # Test frontend and API through nginx (port 80)
        timeout 30 bash -c 'until curl -f http://localhost:80; do sleep 2; done'
        timeout 30 bash -c 'until curl -f http://localhost:80/health; do sleep 2; done'
        
        # Cleanup
        docker compose down -v

  deploy:
    needs: [integration-tests, docker-build, deepsource, monitoring]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - name: Deploy notification
      run: |
        echo "ðŸš€ All checks passed! Ready for deployment"
        echo "ðŸ“Š Test Results: All tests passed"
        echo "ðŸ”§ Next steps: Manual review and approval for production deployment"

  deepsource:
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend]
    if: always() && (needs.test-backend.result == 'success' || needs.test-frontend.result == 'success')
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: |
          requirements.txt
          requirements-dev.txt
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        
    - name: Generate test coverage
      env:
        PYTHONPATH: .
        FLASK_ENV: testing
      run: |
        python -m pytest tests/ --cov=src --cov-report=xml --cov-report=html --tb=short
        
    - name: Upload coverage to DeepSource
      env:
        DEEPSOURCE_DSN: ${{ secrets.DEEPSOURCE_DSN }}
      run: |
        if [ ! -z "$DEEPSOURCE_DSN" ]; then
          echo "ðŸ“Š Uploading coverage to DeepSource..."
          
          # Install DeepSource CLI with error handling
          if curl -fsSL https://deepsource.io/cli | sh; then
            echo "âœ… DeepSource CLI installed successfully"
            
            # Report coverage with error handling
            if ./bin/deepsource report --analyzer test-coverage --key python --value-file ./coverage.xml; then
              echo "âœ… Coverage reported to DeepSource successfully"
            else
              echo "âš ï¸ Failed to upload coverage to DeepSource"
              echo "This may be due to network issues or invalid DSN"
              exit 0  # Don't fail the entire pipeline for DeepSource issues
            fi
          else
            echo "âš ï¸ Failed to install DeepSource CLI"
            echo "This may be due to network connectivity issues"
            echo "Coverage data is still available as artifacts"
            exit 0  # Don't fail the entire pipeline for installation issues
          fi
        else
          echo "âš ï¸ DeepSource DSN not configured, skipping coverage upload"
          echo "â„¹ï¸ To enable DeepSource integration, add DEEPSOURCE_DSN to repository secrets"
          echo "â„¹ï¸ Visit https://deepsource.io to get your DSN token"
        fi
        
    - name: Upload coverage artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-reports
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30

  monitoring:
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend, code-quality, integration-tests, deepsource]
    if: always()
    steps:
    - name: Pipeline status monitoring
      run: |
        echo "=== CI/CD Pipeline Status Summary ==="
        echo "Timestamp: $(date)"
        echo "Repository: ${{ github.repository }}"
        echo "Branch: ${{ github.ref_name }}"
        echo "Commit: ${{ github.sha }}"
        echo ""
        echo "Job Results:"
        echo "  test-backend: ${{ needs.test-backend.result }}"
        echo "  test-frontend: ${{ needs.test-frontend.result }}"
        echo "  code-quality: ${{ needs.code-quality.result }}"
        echo "  integration-tests: ${{ needs.integration-tests.result }}"
        echo "  deepsource: ${{ needs.deepsource.result }}"
        echo ""
        
        # Calculate success rate with safer arithmetic
        TOTAL=5
        SUCCESS=0
        [[ "${{ needs.test-backend.result }}" == "success" ]] && SUCCESS=$((SUCCESS + 1)) || true
        [[ "${{ needs.test-frontend.result }}" == "success" ]] && SUCCESS=$((SUCCESS + 1)) || true
        [[ "${{ needs.code-quality.result }}" == "success" ]] && SUCCESS=$((SUCCESS + 1)) || true
        [[ "${{ needs.integration-tests.result }}" == "success" ]] && SUCCESS=$((SUCCESS + 1)) || true
        [[ "${{ needs.deepsource.result }}" == "success" ]] && SUCCESS=$((SUCCESS + 1)) || true
        
        SUCCESS_RATE=$((SUCCESS * 100 / TOTAL))
        echo "Success Rate: ${SUCCESS_RATE}% (${SUCCESS}/${TOTAL})"
        echo ""
        
        if [ $SUCCESS_RATE -eq 100 ]; then
          echo "âœ… All core pipeline jobs completed successfully!"
          echo "ðŸš€ Pipeline ready for deployment"
        elif [ $SUCCESS_RATE -ge 80 ]; then
          echo "âš ï¸ Pipeline mostly successful with some issues"
          echo "ðŸ“Š Review failed jobs before deployment"
        else
          echo "âŒ Pipeline has significant failures"
          echo "ðŸ”§ Address failing jobs before proceeding"
        fi
        
        # Export metrics for potential future use
        echo "success_rate=${SUCCESS_RATE}" >> $GITHUB_OUTPUT
        echo "total_jobs=${TOTAL}" >> $GITHUB_OUTPUT
        echo "successful_jobs=${SUCCESS}" >> $GITHUB_OUTPUT
        
        # Always exit successfully - monitoring is informational only
        echo ""
        echo "ðŸ“ˆ Monitoring completed successfully"
        exit 0