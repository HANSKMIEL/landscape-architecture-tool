name: Performance Monitoring

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC

permissions:
  contents: read
  actions: write

jobs:
  performance-test:
    name: Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: app_test
        ports: ["5432:5432"]
        options: >-
          --health-cmd="pg_isready -U postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=15

    env:
      DATABASE_URL: postgresql://postgres:postgres@localhost:5432/app_test
      FLASK_ENV: testing
      PYTHONPATH: .

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install locust pytest-benchmark

      - name: Setup database
        run: |
          python -c "
          from src.models.user import db
          from src.main import create_app
          
          app = create_app()
          with app.app_context():
              db.create_all()
          "

      - name: Run performance benchmarks
        run: |
          echo "ðŸš€ Running performance benchmarks..."
          pytest tests/ -k "benchmark" --benchmark-json=benchmark-results.json || true

      - name: API Load Testing
        run: |
          echo "ðŸ”„ Running API load tests..."
          # Start the application in background
          python src/main.py &
          APP_PID=$!
          
          # Wait for app to start
          sleep 10
          
          # Run load tests
          cat > locustfile.py << 'EOF'
          from locust import HttpUser, task, between

          class AuthenticatedUser(HttpUser):
              wait_time = between(1, 3)

              def on_start(self):
                  # Create a test user and log in to get a session cookie
                  self.client.post("/api/auth/register", json={"username": "testuser", "password": "password"})
                  self.client.post("/api/auth/login", json={"username": "testuser", "password": "password"})

              @task(3)
              def view_dashboard(self):
                  self.client.get("/api/dashboard/stats")

              @task(2)
              def view_suppliers(self):
                  self.client.get("/api/suppliers")

              @task(2)
              def view_plants(self):
                  self.client.get("/api/plants")

              @task(1)
              def view_projects(self):
                  self.client.get("/api/projects")
          EOF
          
          locust -f locustfile.py --headless --users 10 --spawn-rate 2 --run-time 60s --host http://localhost:5000 --html performance-report.html
          
          # Stop the application
          kill $APP_PID || true

      - name: Frontend Performance Testing
        run: |
          echo "ðŸŒ Running frontend performance tests..."
          cd frontend
          npm ci
          npm run build
          
          # Install lighthouse
          npm install -g lighthouse
          
          # Start frontend server
          npm run preview &
          FRONTEND_PID=$!
          
          # Wait for server to start
          sleep 10
          
          # Run lighthouse audit
          lighthouse http://localhost:4173 --output=json --output-path=lighthouse-report.json --chrome-flags="--headless --no-sandbox" || true
          
          # Stop frontend server
          kill $FRONTEND_PID || true

      - name: Upload performance artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports-${{ github.run_number }}
          path: |
            benchmark-results.json
            performance-report.html
            lighthouse-report.json
          retention-days: 30
